{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzHOBpCXjnBQrJXUJhftTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tingleica/FundingAnalysis/blob/main/ChatGPTCodeDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To install yfinance in Google Colab, you can use the following command:\n",
        "\n",
        "!pip install yfinance\n",
        "You can run this command in a code cell in your Colab notebook.\n",
        "\n",
        "Here's an example of how you can install yfinance and use it to download historical prices of a stock in Colab:\n",
        "\n"
      ],
      "metadata": {
        "id": "rmaMwhLqBDMd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zwZL3JYAWfP"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "\n",
        "import yfinance as yf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data and calculate returns"
      ],
      "metadata": {
        "id": "Xe3xiXGBsbql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "write python code for google colab to download historical prices for a list of stocks saved in a csv file, the calculate the daily returns, and save all of the data and results in a excel file in a local drive"
      ],
      "metadata": {
        "id": "28-6y1U_Kppr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# Load the list of stocks from the CSV file\n",
        "stocks_csv_path = \"/content/SP500List.csv\"  # Update with the path to your CSV file\n",
        "stocks_df = pd.read_csv(stocks_csv_path)\n",
        "\n",
        "# Create an empty DataFrame to store the combined data\n",
        "combined_data = pd.DataFrame()\n",
        "\n",
        "# Create an empty DataFrame to store the daily returns\n",
        "returns_data = pd.DataFrame()\n",
        "# Download historical prices for each stock\n",
        "start_date = \"2013-01-01\"\n",
        "end_date = \"2023-07-06\"\n",
        "\n",
        "for TICKER in stocks_df['TICKER']:\n",
        "    stock = yf.download(TICKER, start=start_date, end=end_date, interval='1mo')\n",
        "    stock_data = stock[['Adj Close']].rename(columns={'Adj Close': TICKER})\n",
        "    combined_data = pd.concat([combined_data, stock_data], axis=1)\n",
        "    #returns_data[TICKER] = stock_data.pct_change().iloc[:, 0]\n",
        "    returns_data = pd.concat([returns_data, stock_data.pct_change().iloc[:, 0]], axis=1)\n",
        "# Save the combined data to an Excel file\n",
        "excel_file_path = \"/content/stock_data.xlsx\"  # Update with the desired path for the Excel file\n",
        "\n",
        "with pd.ExcelWriter(excel_file_path) as writer:\n",
        "    combined_data.to_excel(writer, sheet_name='Combined Data', index_label='Date')\n",
        "\n",
        "print(\"Combined data has been saved to:\", excel_file_path)\n",
        "\n",
        "# Save the daily returns to a CSV file\n",
        "returns_csv_path = \"/content/returns_data.csv\"  # Update with the desired path for the CSV file\n",
        "\n",
        "returns_data.to_csv(returns_csv_path, index_label='Date')\n",
        "\n",
        "print(\"Returns have been saved to:\", returns_csv_path)\n"
      ],
      "metadata": {
        "id": "FcNzmlCAKuea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9e8cc97-3e44-4684-c711-1f9567f688ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-464ba46439d5>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mTICKER\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstocks_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TICKER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mstock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTICKER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1mo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mstock_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTICKER\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcombined_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yfinance/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mIndentationContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Exiting {func.__name__}()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yfinance/multi.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, show_errors, interval, prepost, proxy, rounding, timeout, session)\u001b[0m\n\u001b[1;32m    155\u001b[0m                                    rounding=rounding, timeout=timeout, session=session)\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DFS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0m_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;31m# download synchronously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression between each stock in the SP500 list and SPX"
      ],
      "metadata": {
        "id": "mAlmnqEytxQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the daily returns from the CSV file\n",
        "returns_csv_path = \"/content/returns_data.csv\"  # Update with the path to your CSV file\n",
        "returns_data = pd.read_csv(returns_csv_path, index_col=0)\n",
        "\n",
        "# Perform regression for each TICKER with SPY as the independent variable\n",
        "regression_results = pd.DataFrame(columns=[\"TICKER\", \"Slope\", \"Intercept\", \"R-squared\"])\n",
        "\n",
        "# Select SPY as the independent variable\n",
        "x = returns_data['SPY']\n",
        "\n",
        "for TICKER in returns_data.columns:\n",
        "    if TICKER != 'SPY':\n",
        "        y = returns_data[TICKER]\n",
        "\n",
        "        # Remove missing Y values\n",
        "        data = pd.concat([x, y], axis=1).dropna()\n",
        "        x_cleaned = data['SPY']\n",
        "        y_cleaned = data[TICKER]\n",
        "\n",
        "        # Add constant term to independent variable\n",
        "        x_cleaned = sm.add_constant(x_cleaned)\n",
        "\n",
        "        # Fit linear regression model\n",
        "        model = sm.OLS(y_cleaned, x_cleaned)\n",
        "        results = model.fit()\n",
        "\n",
        "        # Store regression results\n",
        "        slope = results.params[1]\n",
        "        intercept = results.params[0]\n",
        "        r_squared = results.rsquared\n",
        "        regression_results = regression_results.append({\"TICKER\": TICKER, \"Slope\": slope, \"Intercept\": intercept, \"R-squared\": r_squared}, ignore_index=True)\n",
        "\n",
        "# Save the regression results to a CSV file\n",
        "regression_csv_path = \"/content/regression_results.csv\"  # Update with the desired path for the CSV file\n",
        "regression_results.to_csv(regression_csv_path, index=False)\n",
        "\n",
        "print(\"Regression results have been saved to:\", regression_csv_path)\n"
      ],
      "metadata": {
        "id": "BVG0ubw8q0cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the daily returns from the CSV file\n",
        "returns_csv_path = \"/content/returns_data.csv\"  # Update with the path to your CSV file\n",
        "returns_data = pd.read_csv(returns_csv_path, index_col=0)\n",
        "\n",
        "# Perform regression for each TICKER with SPY as the independent variable\n",
        "regression_results = pd.DataFrame(columns=[\"TICKER\", \"Slope\", \"Intercept\", \"R-squared\"])\n",
        "\n",
        "# Select SPY as the independent variable\n",
        "x = returns_data['SPY']\n",
        "\n",
        "# Create an empty DataFrame to store the predicted Y values and errors\n",
        "predicted_values = pd.DataFrame(index=x.index)\n",
        "errors = pd.DataFrame(index=x.index)\n",
        "\n",
        "for TICKER in returns_data.columns:\n",
        "    if TICKER != 'SPY':\n",
        "        y = returns_data[TICKER]\n",
        "\n",
        "        # Remove missing Y values\n",
        "        data = pd.concat([x, y], axis=1).dropna()\n",
        "        x_cleaned = data['SPY']\n",
        "        y_cleaned = data[TICKER]\n",
        "\n",
        "        # Add constant term to independent variable\n",
        "        x_cleaned = sm.add_constant(x_cleaned)\n",
        "\n",
        "        # Fit linear regression model\n",
        "        model = sm.OLS(y_cleaned, x_cleaned)\n",
        "        results = model.fit()\n",
        "\n",
        "        # Store regression results\n",
        "        slope = results.params[1]\n",
        "        intercept = results.params[0]\n",
        "        r_squared = results.rsquared\n",
        "        regression_results = regression_results.append({\"TICKER\": TICKER, \"Slope\": slope, \"Intercept\": intercept, \"R-squared\": r_squared}, ignore_index=True)\n",
        "\n",
        "        # Calculate predicted Y values\n",
        "        predicted_y = results.predict(x_cleaned)\n",
        "        predicted_values[TICKER] = predicted_y\n",
        "\n",
        "        # Calculate error (difference between actual Y and predicted Y)\n",
        "        error = y_cleaned - predicted_y\n",
        "        errors[TICKER] = error\n",
        "\n",
        "# Save the regression results to a CSV file\n",
        "regression_csv_path = \"/content/regression_results.csv\"  # Update with the desired path for the CSV file\n",
        "regression_results.to_csv(regression_csv_path, index=False)\n",
        "\n",
        "print(\"Regression results have been saved to:\", regression_csv_path)\n",
        "\n",
        "# Save the predicted Y values to a CSV file\n",
        "predicted_csv_path = \"/content/predicted_values.csv\"  # Update with the desired path for the CSV file\n",
        "predicted_values.to_csv(predicted_csv_path)\n",
        "\n",
        "print(\"Predicted Y values have been saved to:\", predicted_csv_path)\n",
        "\n",
        "# Save the errors to a CSV file\n",
        "errors_csv_path = \"/content/errors.csv\"  # Update with the desired path for the CSV file\n",
        "errors.to_csv(errors_csv_path)\n",
        "\n",
        "print(\"Errors have been saved to:\", errors_csv_path)\n"
      ],
      "metadata": {
        "id": "-b55Wd94sxxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate correlation matrix for error terms"
      ],
      "metadata": {
        "id": "qPQaxwa2xy5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the daily returns from the CSV file\n",
        "returns_csv_path = \"/content/returns_data.csv\"  # Update with the path to your CSV file\n",
        "returns_data = pd.read_csv(returns_csv_path, index_col=0)\n",
        "\n",
        "# Perform regression for each TICKER with SPY as the independent variable\n",
        "regression_results = pd.DataFrame(columns=[\"TICKER\", \"Slope\", \"Intercept\", \"R-squared\"])\n",
        "\n",
        "# Select SPY as the independent variable\n",
        "x = returns_data['SPY']\n",
        "\n",
        "# Create an empty DataFrame to store the predicted Y values and errors\n",
        "predicted_values = pd.DataFrame(index=x.index)\n",
        "errors = pd.DataFrame(index=x.index)\n",
        "\n",
        "for TICKER in returns_data.columns:\n",
        "    if TICKER != 'SPY':\n",
        "        y = returns_data[TICKER]\n",
        "\n",
        "        # Remove missing Y values\n",
        "        data = pd.concat([x, y], axis=1).dropna()\n",
        "        x_cleaned = data['SPY']\n",
        "        y_cleaned = data[TICKER]\n",
        "\n",
        "        # Add constant term to independent variable\n",
        "        x_cleaned = sm.add_constant(x_cleaned)\n",
        "\n",
        "        # Fit linear regression model\n",
        "        model = sm.OLS(y_cleaned, x_cleaned)\n",
        "        results = model.fit()\n",
        "\n",
        "        # Store regression results\n",
        "        slope = results.params[1]\n",
        "        intercept = results.params[0]\n",
        "        r_squared = results.rsquared\n",
        "        regression_results = regression_results.append({\"TICKER\": TICKER, \"Slope\": slope, \"Intercept\": intercept, \"R-squared\": r_squared}, ignore_index=True)\n",
        "\n",
        "        # Calculate predicted Y values\n",
        "        predicted_y = results.predict(x_cleaned)\n",
        "        predicted_values[TICKER] = predicted_y\n",
        "\n",
        "        # Calculate error (difference between actual Y and predicted Y)\n",
        "        error = y_cleaned - predicted_y\n",
        "        errors[TICKER] = error\n",
        "\n",
        "# Calculate the correlation matrix for the errors\n",
        "correlation_matrix = errors.corr(method='pearson')\n",
        "\n",
        "# Save the regression results to a CSV file\n",
        "regression_csv_path = \"/content/regression_results.csv\"  # Update with the desired path for the CSV file\n",
        "regression_results.to_csv(regression_csv_path, index=False)\n",
        "\n",
        "print(\"Regression results have been saved to:\", regression_csv_path)\n",
        "\n",
        "# Save the predicted Y values to a CSV file\n",
        "predicted_csv_path = \"/content/predicted_values.csv\"  # Update with the desired path for the CSV file\n",
        "predicted_values.to_csv(predicted_csv_path)\n",
        "\n",
        "print(\"Predicted Y values have been saved to:\", predicted_csv_path)\n",
        "\n",
        "# Save the errors to a CSV file\n",
        "errors_csv_path = \"/content/errors.csv\"  # Update with the desired path for the CSV file\n",
        "errors.to_csv(errors_csv_path)\n",
        "\n",
        "print(\"Errors have been saved to:\", errors_csv_path)\n",
        "\n",
        "# Save the correlation matrix to a CSV file\n",
        "correlation_csv_path = \"/content/correlation_matrix.csv\"  # Update with the desired path for the CSV file\n",
        "correlation_matrix.to_csv(correlation_csv_path)\n",
        "\n",
        "print(\"Correlation matrix has been saved to:\", correlation_csv_path)\n"
      ],
      "metadata": {
        "id": "fsAv2ztiuhN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}